{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Carpark Availability\n",
    "This notebook extracts and clean the carpark data, and thereafter applies a machine learning model on the data to do prediction of carpark lot availability based on the carpark number and the date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential Modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regr = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encode = LabelEncoder()\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essential functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_list(object):\n",
    "#     return list(object)\n",
    "\n",
    "# Convert the string to a datetime object\n",
    "def convert_to_dateTime(object):\n",
    "    return datetime.strptime(object, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Extract the time only from datetime object\n",
    "def takeTimeOnly(time):\n",
    "    return time.strftime('%H:%M:%S')\n",
    "\n",
    "def convertTimeToSec(time):\n",
    "    h, m, s = time.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "def obtainDate(ts):\n",
    "    return ts.strftime('%Y-%m-%d')\n",
    "\n",
    "def obtainHour(ts):\n",
    "    return ts.strftime('%H')\n",
    "\n",
    "def obtainYear(ts):\n",
    "    return ts.strftime('%Y')\n",
    "\n",
    "def checkDayOfWeek(ts):\n",
    "    #daysInWeek = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    count = 0\n",
    "    for i in range(0, 7):\n",
    "        if ts.weekday() == count:\n",
    "            return count\n",
    "        count+=1\n",
    "        \n",
    "def obtainCarParkNumIndicator(listOfCarparks, carparkNumber):\n",
    "    count = 0\n",
    "    for i in listOfCarparks:\n",
    "        if carparkNumber == i:\n",
    "            return count\n",
    "        count+=1\n",
    "\n",
    "def obtainLotTypeIndicator(lotTypes, lotType):\n",
    "    count = 0\n",
    "    for i in lotTypes:\n",
    "        if lotType == i:\n",
    "            return count\n",
    "        count+=1\n",
    "\n",
    "def WeekdayOrWeekend(ts):\n",
    "    day = ts.weekday()\n",
    "    if (day >= 0 and day <= 4):\n",
    "        return 0\n",
    "    elif (day >= 5 and day <= 6): return 1\n",
    "    \n",
    "def identifyCarpark(carpark):\n",
    "    count = 0\n",
    "    for i in allCarparks:\n",
    "        if i == carpark:\n",
    "            return count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data from the file directory\n",
    "The data was previously crawled from the API and store in as a JSON format. As the overall data from the Housing Development Board (HDB) is huge, we split the extracting of data into several parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path_to_jsonfiles = 'URAData\\/'\n",
    "\n",
    "mainURAdf = None\n",
    "counter = 0\n",
    "\n",
    "for file in os.listdir(path_to_jsonfiles):\n",
    "    full_filename = \"%s/%s\" % (path_to_jsonfiles, file)\n",
    "    with open(full_filename,'r') as fi:\n",
    "        d = json.load(fi)\n",
    "        print(\"check\", counter)\n",
    "\n",
    "        for y in range(0,len(d)):#11):\n",
    "            dn = d[y][\"availabilityResults\"]\n",
    "            df = json_normalize(dn)\n",
    "            df[\"timeStamp\"] = d[y][\"timeStamp\"]\n",
    "            if mainURAdf is not None:\n",
    "                mainURAdf = pd.concat([mainURAdf,df], axis=0)\n",
    "            else:\n",
    "                mainURAdf = df\n",
    "    counter+=1\n",
    "\n",
    "mainURAdf = mainURAdf[mainURAdf['lotType'] == 'C']\n",
    "mainURAdf = mainURAdf.sort_values(by = 'timeStamp')\n",
    "mainURAdf = mainURAdf.reset_index()\n",
    "mainURAdf = mainURAdf.drop(columns = ['index', 'lotType'])\n",
    "mainURAdf.to_csv('URAData.csv')\n",
    "mainURAdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ##############################  HDB 1 ##############################################################\n",
    "path_to_jsonfiles = 'HDBData_Json1\\/'\n",
    "mainHDBdf1 = None\n",
    "count = 0\n",
    "\n",
    "#for (i, file) in enumerate(os.listdir(path_to_jsonfiles)):\n",
    "for file in os.listdir(path_to_jsonfiles):\n",
    "    full_filename = \"%s/%s\" % (path_to_jsonfiles, file)\n",
    "    with open(full_filename,'r') as fi:\n",
    "        d = json.load(fi)\n",
    "        print(\"check\", count)\n",
    "        for y in range(0,len(d)):\n",
    "            try:\n",
    "                dn = d[y]['items'][0]['carpark_data']\n",
    "                for z in range(0,len(dn)):\n",
    "                    carparkNum = dn[z]['carpark_number']\n",
    "                    datetimeString = dn[z]['update_datetime']\n",
    "                    datetimeString = datetimeString[:10] + \" \" + datetimeString[11:]\n",
    "                    dn[z]['carparkNo'] = carparkNum\n",
    "                    dn[z]['timeStamp'] = datetimeString\n",
    "                    dn[z]['lotType'] = dn[z]['carpark_info'][0]['lot_type']\n",
    "                    dn[z]['lotsAvailable'] = dn[z]['carpark_info'][0]['lots_available']\n",
    "                    \n",
    "                df = json_normalize(dn)\n",
    "                df = df.drop(['carpark_info'], axis=1)\n",
    "                if mainHDBdf1 is not None:\n",
    "                    mainHDBdf1 = pd.concat([mainHDBdf1,df], axis=0)\n",
    "                else:\n",
    "                    mainHDBdf1 = df\n",
    "            except:\n",
    "                continue\n",
    "        count+=1\n",
    "                \n",
    "# mainHDBdf1.columns = ['carparkNo','lotType','lotsAvailable','timeStamp']\n",
    "mainHDBdf1 = mainHDBdf1.reset_index()\n",
    "\n",
    "mainHDBdf1['year'] = mainHDBdf1['timeStamp'].apply(lambda x: convert_to_dateTime(x))\n",
    "mainHDBdf1['year'] = mainHDBdf1['year'].apply(lambda x: obtainYear(x))\n",
    "mainHDBdf1 = mainHDBdf1[mainHDBdf1['year'] >= '2020']\n",
    "mainHDBdf1 = mainHDBdf1[mainHDBdf1['lotType'] == 'C']\n",
    "mainHDBdf1 = mainHDBdf1.drop(columns = ['index', 'year', 'carpark_number', 'update_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ##############################  HDB 2 ##############################################################\n",
    "path_to_jsonfiles = 'HDBData_Json2\\/'\n",
    "mainHDBdf2 = None\n",
    "count = 0\n",
    "\n",
    "#for (i, file) in enumerate(os.listdir(path_to_jsonfiles)):\n",
    "for file in os.listdir(path_to_jsonfiles):\n",
    "    full_filename = \"%s/%s\" % (path_to_jsonfiles, file)\n",
    "    with open(full_filename,'r') as fi:\n",
    "        d = json.load(fi)\n",
    "        print(\"check\", count)\n",
    "        for y in range(0,len(d)):\n",
    "            try:\n",
    "                dn = d[y]['items'][0]['carpark_data']\n",
    "                for z in range(0,len(dn)):\n",
    "                    carparkNum = dn[z]['carpark_number']\n",
    "                    datetimeString = dn[z]['update_datetime']\n",
    "                    datetimeString = datetimeString[:10] + \" \" + datetimeString[11:]\n",
    "                    dn[z]['carparkNo'] = carparkNum\n",
    "                    dn[z]['timeStamp'] = datetimeString\n",
    "                    dn[z]['lotType'] = dn[z]['carpark_info'][0]['lot_type']\n",
    "                    dn[z]['lotsAvailable'] = dn[z]['carpark_info'][0]['lots_available']\n",
    "                    \n",
    "                df = json_normalize(dn)\n",
    "                df = df.drop(['carpark_info'], axis=1)\n",
    "                if mainHDBdf2 is not None:\n",
    "                    mainHDBdf2 = pd.concat([mainHDBdf2,df], axis=0)\n",
    "                else:\n",
    "                    mainHDBdf2 = df\n",
    "            except:\n",
    "                continue\n",
    "        count+=1\n",
    "                \n",
    "#mainHDBdf2.columns = ['carparkNo','lotType','lotsAvailable','timeStamp']\n",
    "mainHDBdf2 = mainHDBdf2.reset_index()\n",
    "\n",
    "mainHDBdf2['year'] = mainHDBdf2['timeStamp'].apply(lambda x: convert_to_dateTime(x))\n",
    "mainHDBdf2['year'] = mainHDBdf2['year'].apply(lambda x: obtainYear(x))\n",
    "mainHDBdf2 = mainHDBdf2[mainHDBdf2['year'] >= '2020']\n",
    "mainHDBdf2 = mainHDBdf2[mainHDBdf2['lotType'] == 'C']\n",
    "mainHDBdf2 = mainHDBdf2.drop(columns = ['index', 'year', 'carpark_number', 'update_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ##############################  HDB 3 ##############################################################\n",
    "path_to_jsonfiles = 'HDBData_Json3\\/'\n",
    "mainHDBdf3 = None\n",
    "count = 0\n",
    "\n",
    "#for (i, file) in enumerate(os.listdir(path_to_jsonfiles)):\n",
    "for file in os.listdir(path_to_jsonfiles):\n",
    "    full_filename = \"%s/%s\" % (path_to_jsonfiles, file)\n",
    "    with open(full_filename,'r') as fi:\n",
    "        d = json.load(fi)\n",
    "        print(\"check\", count)\n",
    "        for y in range(0,len(d)):\n",
    "            try:\n",
    "                dn = d[y]['items'][0]['carpark_data']\n",
    "                for z in range(0,len(dn)):\n",
    "                    carparkNum = dn[z]['carpark_number']\n",
    "                    datetimeString = dn[z]['update_datetime']\n",
    "                    datetimeString = datetimeString[:10] + \" \" + datetimeString[11:]\n",
    "                    dn[z]['carparkNo'] = carparkNum\n",
    "                    dn[z]['timeStamp'] = datetimeString\n",
    "                    dn[z]['lotType'] = dn[z]['carpark_info'][0]['lot_type']\n",
    "                    dn[z]['lotsAvailable'] = dn[z]['carpark_info'][0]['lots_available']\n",
    "                    \n",
    "                df = json_normalize(dn)\n",
    "                df = df.drop(['carpark_info'], axis=1)\n",
    "                if mainHDBdf3 is not None:\n",
    "                    mainHDBdf3 = pd.concat([mainHDBdf3,df], axis=0)\n",
    "                else:\n",
    "                    mainHDBdf3 = df\n",
    "            except:\n",
    "                continue\n",
    "        count+=1\n",
    "                \n",
    "#mainHDBdf3.columns = ['carparkNo','lotType','lotsAvailable','timeStamp']\n",
    "mainHDBdf3 = mainHDBdf3.reset_index()\n",
    "\n",
    "mainHDBdf3['year'] = mainHDBdf3['timeStamp'].apply(lambda x: convert_to_dateTime(x))\n",
    "mainHDBdf3['year'] = mainHDBdf3['year'].apply(lambda x: obtainYear(x))\n",
    "mainHDBdf3 = mainHDBdf3[mainHDBdf3['year'] >= '2020']\n",
    "mainHDBdf3 = mainHDBdf3[mainHDBdf3['lotType'] == 'C']\n",
    "mainHDBdf3 = mainHDBdf3.drop(columns = ['index', 'year', 'carpark_number', 'update_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ##############################  HDB 4 ##############################################################\n",
    "path_to_jsonfiles = 'HDBData_Json4\\/'\n",
    "mainHDBdf4 = None\n",
    "count = 0\n",
    "\n",
    "#for (i, file) in enumerate(os.listdir(path_to_jsonfiles)):\n",
    "for file in os.listdir(path_to_jsonfiles):\n",
    "    full_filename = \"%s/%s\" % (path_to_jsonfiles, file)\n",
    "    with open(full_filename,'r') as fi:\n",
    "        d = json.load(fi)\n",
    "        print(\"check\", count)\n",
    "        for y in range(0,len(d)):\n",
    "            try:\n",
    "                dn = d[y]['items'][0]['carpark_data']\n",
    "                for z in range(0,len(dn)):\n",
    "                    carparkNum = dn[z]['carpark_number']\n",
    "                    datetimeString = dn[z]['update_datetime']\n",
    "                    datetimeString = datetimeString[:10] + \" \" + datetimeString[11:]\n",
    "                    dn[z]['carparkNo'] = carparkNum\n",
    "                    dn[z]['timeStamp'] = datetimeString\n",
    "                    dn[z]['lotType'] = dn[z]['carpark_info'][0]['lot_type']\n",
    "                    dn[z]['lotsAvailable'] = dn[z]['carpark_info'][0]['lots_available']\n",
    "                    \n",
    "                df = json_normalize(dn)\n",
    "                df = df.drop(['carpark_info'], axis=1)\n",
    "                if mainHDBdf4 is not None:\n",
    "                    mainHDBdf4 = pd.concat([mainHDBdf4,df], axis=0)\n",
    "                else:\n",
    "                    mainHDBdf4 = df\n",
    "            except:\n",
    "                continue\n",
    "        count+=1\n",
    "                \n",
    "#mainHDBdf4.columns = ['carparkNo','lotType','lotsAvailable','timeStamp']\n",
    "mainHDBdf4 = mainHDBdf4.reset_index()\n",
    "\n",
    "mainHDBdf4['year'] = mainHDBdf4['timeStamp'].apply(lambda x: convert_to_dateTime(x))\n",
    "mainHDBdf4['year'] = mainHDBdf4['year'].apply(lambda x: obtainYear(x))\n",
    "mainHDBdf4 = mainHDBdf4[mainHDBdf4['year'] >= '2020']\n",
    "mainHDBdf4 = mainHDBdf4[mainHDBdf4['lotType'] == 'C']\n",
    "mainHDBdf4 = mainHDBdf4.drop(columns = ['index', 'year', 'carpark_number', 'update_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################  HDB 5 ##############################################################\n",
    "path_to_jsonfiles = 'HDBData_Json5\\/'\n",
    "mainHDBdf5 = None\n",
    "count = 0\n",
    "\n",
    "#for (i, file) in enumerate(os.listdir(path_to_jsonfiles)):\n",
    "for file in os.listdir(path_to_jsonfiles):\n",
    "    full_filename = \"%s/%s\" % (path_to_jsonfiles, file)\n",
    "    with open(full_filename,'r') as fi:\n",
    "        d = json.load(fi)\n",
    "        print(\"check\", count)\n",
    "        for y in range(0,len(d)):\n",
    "            try:\n",
    "                dn = d[y]['items'][0]['carpark_data']\n",
    "                for z in range(0,len(dn)):\n",
    "                    carparkNum = dn[z]['carpark_number']\n",
    "                    datetimeString = dn[z]['update_datetime']\n",
    "                    datetimeString = datetimeString[:10] + \" \" + datetimeString[11:]\n",
    "                    dn[z]['carparkNo'] = carparkNum\n",
    "                    dn[z]['timeStamp'] = datetimeString\n",
    "                    dn[z]['lotType'] = dn[z]['carpark_info'][0]['lot_type']\n",
    "                    dn[z]['lotsAvailable'] = dn[z]['carpark_info'][0]['lots_available']\n",
    "                    \n",
    "                df = json_normalize(dn)\n",
    "                df = df.drop(['carpark_info'], axis=1)\n",
    "                if mainHDBdf5 is not None:\n",
    "                    mainHDBdf5 = pd.concat([mainHDBdf5,df], axis=0)\n",
    "                else:\n",
    "                    mainHDBdf5 = df\n",
    "            except:\n",
    "                continue\n",
    "        count+=1\n",
    "                \n",
    "#mainHDBdf5.columns = ['carparkNo','lotType','lotsAvailable','timeStamp']\n",
    "mainHDBdf5 = mainHDBdf5.reset_index()\n",
    "\n",
    "mainHDBdf5['year'] = mainHDBdf5['timeStamp'].apply(lambda x: convert_to_dateTime(x))\n",
    "mainHDBdf5['year'] = mainHDBdf5['year'].apply(lambda x: obtainYear(x))\n",
    "mainHDBdf5 = mainHDBdf5[mainHDBdf5['year'] >= '2020']\n",
    "mainHDBdf5 = mainHDBdf5[mainHDBdf5['lotType'] == 'C']\n",
    "mainHDBdf5 = mainHDBdf5.drop(columns = ['index', 'year', 'carpark_number', 'update_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the extraction of data was done in several parts, we concatenate the different parts into 1 single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainHDBdf = pd.concat([mainHDBdf1, mainHDBdf2, mainHDBdf3, mainHDBdf4, mainHDBdf5])\n",
    "\n",
    "mainHDBdf = mainHDBdf.drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Features Extraction\n",
    "Cleaning of the data, and getting features from the original attributes.\n",
    "The original data has the following attributes, carpark number, date and time, and the carpark lot availability. Hence, with the date and time of each data point, we generate the details such as the time in seconds ('timeInSec'), the hour ('hour') and the day of the week ('dayOfWeek')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainURAdf['timeStamp'] = mainURAdf['timeStamp'].apply(lambda x: convert_to_dateTime(x))\n",
    "mainURAdf['dayOfWeek'] = mainURAdf['timeStamp'].apply(lambda x: checkDayOfWeek(x))\n",
    "mainURAdf['hour'] = mainURAdf['timeStamp'].apply(lambda x: obtainHour(x))\n",
    "mainURAdf['timeOnly'] = mainURAdf['timeStamp'].apply(lambda x: takeTimeOnly(x))\n",
    "mainURAdf['timeInSec'] = mainURAdf['timeOnly'].apply(lambda x: convertTimeToSec(x))\n",
    "mainURAdf['lotsAvailable'] = mainURAdf['lotsAvailable'].apply(lambda x: int(x))\n",
    "lotsURA = mainURAdf.lotsAvailable\n",
    "mainURAdf = mainURAdf.drop(columns = ['timeOnly', 'lotsAvailable'])\n",
    "mainURAdf = pd.concat([mainURAdf, lotsURA], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainHDBdf['timeStamp'] = mainHDBdf['timeStamp'].apply(lambda x: convert_to_dateTime(x))\n",
    "mainHDBdf['dayOfWeek'] = mainHDBdf['timeStamp'].apply(lambda x: checkDayOfWeek(x))\n",
    "mainHDBdf['hour'] = mainHDBdf['timeStamp'].apply(lambda x: obtainHour(x))\n",
    "mainHDBdf['timeOnly'] = mainHDBdf['timeStamp'].apply(lambda x: takeTimeOnly(x))\n",
    "mainHDBdf['timeInSec'] = mainHDBdf['timeOnly'].apply(lambda x: convertTimeToSec(x))\n",
    "mainHDBdf['lotsAvailable'] = mainHDBdf['lotsAvailable'].apply(lambda x: int(x))\n",
    "lotsHDB = mainHDBdf.lotsAvailable\n",
    "mainHDBdf = mainHDBdf.drop(columns = ['index', 'Unnamed: 0', 'lotType', 'timeOnly', 'lotsAvailable'])\n",
    "mainHDBdf = pd.concat([mainHDBdf, lotsHDB], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thereafter, we combine the data from both the HDB and the URA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carparkNo</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>hour</th>\n",
       "      <th>timeInSec</th>\n",
       "      <th>lotsAvailable</th>\n",
       "      <th>carparkNoIndicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:34:05</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>48845</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:34:05</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>48845</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:39:07</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>49147</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:39:07</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>49147</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:44:09</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>49449</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  carparkNo            timeStamp  dayOfWeek  hour  timeInSec  lotsAvailable  \\\n",
       "0     S0049  2020-02-05 13:34:05          2    13      48845            107   \n",
       "1     S0049  2020-02-05 13:34:05          2    13      48845            107   \n",
       "2     S0049  2020-02-05 13:39:07          2    13      49147            107   \n",
       "3     S0049  2020-02-05 13:39:07          2    13      49147            107   \n",
       "4     S0049  2020-02-05 13:44:09          2    13      49449            107   \n",
       "\n",
       "   carparkNoIndicator  \n",
       "0                1140  \n",
       "1                1140  \n",
       "2                1140  \n",
       "3                1140  \n",
       "4                1140  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDF = pd.concat([mainURAdf, mainHDBdf])\n",
    "# combinedDF = combinedDF.drop(columns = ['Unnamed: 0', 'modelParts'])\n",
    "combinedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of carparks from the data are also saved into a seperate CSV file for record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"----------URA----------\")\n",
    "# print(mainURAdf.carparkNo.unique(), \"\\n\")\n",
    "# print(\"Total number of carpaks: \", len(mainURAdf.carparkNo.unique()), \"\\n\")\n",
    "\n",
    "# listOfURACarparks = list(mainURAdf.carparkNo.unique())\n",
    "\n",
    "# print(\"----------HDB----------\")\n",
    "# print(mainHDBdf.carparkNo.unique(), \"\\n\")\n",
    "# print(\"Total number of carpaks: \", len(mainHDBdf.carparkNo.unique()), \"\\n\")\n",
    "\n",
    "listOfHDBCarparks = list(mainHDBdf.carparkNo.unique())\n",
    "\n",
    "allCarparks = listOfURACarparks + listOfHDBCarparks\n",
    "\n",
    "allCarparks = list(combinedDF.carparkNo.unique())\n",
    "\n",
    "allCarparks.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "usedCarparks = pd.DataFrame(allCarparks, index =list(range(0, len(allCarparks))), columns =['carparkNo']) \n",
    "# usedCarparks.to_csv('usedCarparks.csv')\n",
    "# print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding of indicator data\n",
      "\n",
      "Day of week\n",
      "\n",
      "Monday : \t 0\n",
      "Tuesday : \t 1\n",
      "Wednesday : \t 2\n",
      "Thursday : \t 3\n",
      "Friday : \t 4\n",
      "Saturday : \t 5\n",
      "Sunday : \t 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Understanding of indicator data\")\n",
    "\n",
    "print(\"\\nDay of week\\n\")\n",
    "daysOfWeek = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "count = 0\n",
    "for i in daysOfWeek:\n",
    "    print(i, \": \\t\", count)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of Data\n",
    "The carpark number in the data frame is encoded as it is in string type. We encode and convert the carpark numbers to integer using the sklearn Label Encoder. As the Label Encoder encodes the variable in alphabetical order, we need the used carparks data frame as an understanding to which encoded number is to which carpark. The used carparks data frame has been sorted in alphabetical order as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carparkNo</th>\n",
       "      <th>modelParts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  carparkNo  modelParts\n",
       "0     A0007           0\n",
       "1     A0021           0\n",
       "2     A0024           0\n",
       "3     A0046           0\n",
       "4       A10           0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usedCarparks = pd.read_csv('usedCarparks.csv')\n",
    "usedCarparks = usedCarparks.drop(columns = ['Unnamed: 0'])\n",
    "usedCarparks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carparkNo</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>hour</th>\n",
       "      <th>timeInSec</th>\n",
       "      <th>lotsAvailable</th>\n",
       "      <th>carparkNoIndicator</th>\n",
       "      <th>modelParts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:34:05</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>48845</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:34:05</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>48845</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:39:07</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>49147</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:39:07</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>49147</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0049</td>\n",
       "      <td>2020-02-05 13:44:09</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>49449</td>\n",
       "      <td>107</td>\n",
       "      <td>1140</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519606</th>\n",
       "      <td>SK53</td>\n",
       "      <td>2020-02-29 09:41:02</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>34862</td>\n",
       "      <td>400</td>\n",
       "      <td>1336</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519607</th>\n",
       "      <td>SK53</td>\n",
       "      <td>2020-02-29 09:43:02</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>34982</td>\n",
       "      <td>400</td>\n",
       "      <td>1336</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519608</th>\n",
       "      <td>SK53</td>\n",
       "      <td>2020-02-29 09:45:02</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>35102</td>\n",
       "      <td>400</td>\n",
       "      <td>1336</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519609</th>\n",
       "      <td>SK53</td>\n",
       "      <td>2020-02-29 09:47:02</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>35222</td>\n",
       "      <td>400</td>\n",
       "      <td>1336</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519610</th>\n",
       "      <td>SK53</td>\n",
       "      <td>2020-02-29 09:50:02</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>35402</td>\n",
       "      <td>400</td>\n",
       "      <td>1336</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26519611 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         carparkNo            timeStamp  dayOfWeek  hour  timeInSec  \\\n",
       "0            S0049  2020-02-05 13:34:05          2    13      48845   \n",
       "1            S0049  2020-02-05 13:34:05          2    13      48845   \n",
       "2            S0049  2020-02-05 13:39:07          2    13      49147   \n",
       "3            S0049  2020-02-05 13:39:07          2    13      49147   \n",
       "4            S0049  2020-02-05 13:44:09          2    13      49449   \n",
       "...            ...                  ...        ...   ...        ...   \n",
       "26519606      SK53  2020-02-29 09:41:02          5     9      34862   \n",
       "26519607      SK53  2020-02-29 09:43:02          5     9      34982   \n",
       "26519608      SK53  2020-02-29 09:45:02          5     9      35102   \n",
       "26519609      SK53  2020-02-29 09:47:02          5     9      35222   \n",
       "26519610      SK53  2020-02-29 09:50:02          5     9      35402   \n",
       "\n",
       "          lotsAvailable  carparkNoIndicator  modelParts  \n",
       "0                   107                1140          19  \n",
       "1                   107                1140          19  \n",
       "2                   107                1140          19  \n",
       "3                   107                1140          19  \n",
       "4                   107                1140          19  \n",
       "...                 ...                 ...         ...  \n",
       "26519606            400                1336          22  \n",
       "26519607            400                1336          22  \n",
       "26519608            400                1336          22  \n",
       "26519609            400                1336          22  \n",
       "26519610            400                1336          22  \n",
       "\n",
       "[26519611 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedDF['carparkNoIndicator'] = encode.fit_transform(combinedDF['carparkNo'])\n",
    "combinedDF = pd.merge(combinedDF, usedCarparks, on = \"carparkNo\")\n",
    "combinedDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply with Decision Tree Regression\n",
    "sklearn Decision Tree Regression has been chosen for the model to train the data and predict the carpark availability. This represents a regression problem with categorical predictors. As the saved model is set to be huge due to the large data frame, we will need to seperate the data frame based on carparks numbers then apply models on the carpark numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combinedDF_part0 = combinedDF[combinedDF['modelParts'] == 0 ]\n",
      "combinedDF_part1 = combinedDF[combinedDF['modelParts'] == 1 ]\n",
      "combinedDF_part2 = combinedDF[combinedDF['modelParts'] == 2 ]\n",
      "combinedDF_part3 = combinedDF[combinedDF['modelParts'] == 3 ]\n",
      "combinedDF_part4 = combinedDF[combinedDF['modelParts'] == 4 ]\n",
      "combinedDF_part5 = combinedDF[combinedDF['modelParts'] == 5 ]\n",
      "combinedDF_part6 = combinedDF[combinedDF['modelParts'] == 6 ]\n",
      "combinedDF_part7 = combinedDF[combinedDF['modelParts'] == 7 ]\n",
      "combinedDF_part8 = combinedDF[combinedDF['modelParts'] == 8 ]\n",
      "combinedDF_part9 = combinedDF[combinedDF['modelParts'] == 9 ]\n",
      "combinedDF_part10 = combinedDF[combinedDF['modelParts'] == 10 ]\n",
      "combinedDF_part11 = combinedDF[combinedDF['modelParts'] == 11 ]\n",
      "combinedDF_part12 = combinedDF[combinedDF['modelParts'] == 12 ]\n",
      "combinedDF_part13 = combinedDF[combinedDF['modelParts'] == 13 ]\n",
      "combinedDF_part14 = combinedDF[combinedDF['modelParts'] == 14 ]\n",
      "combinedDF_part15 = combinedDF[combinedDF['modelParts'] == 15 ]\n",
      "combinedDF_part16 = combinedDF[combinedDF['modelParts'] == 16 ]\n",
      "combinedDF_part17 = combinedDF[combinedDF['modelParts'] == 17 ]\n",
      "combinedDF_part18 = combinedDF[combinedDF['modelParts'] == 18 ]\n",
      "combinedDF_part19 = combinedDF[combinedDF['modelParts'] == 19 ]\n",
      "combinedDF_part20 = combinedDF[combinedDF['modelParts'] == 20 ]\n",
      "combinedDF_part21 = combinedDF[combinedDF['modelParts'] == 21 ]\n",
      "combinedDF_part22 = combinedDF[combinedDF['modelParts'] == 22 ]\n",
      "combinedDF_part23 = combinedDF[combinedDF['modelParts'] == 23 ]\n",
      "combinedDF_part24 = combinedDF[combinedDF['modelParts'] == 24 ]\n",
      "combinedDF_part25 = combinedDF[combinedDF['modelParts'] == 25 ]\n",
      "combinedDF_part26 = combinedDF[combinedDF['modelParts'] == 26 ]\n",
      "combinedDF_part27 = combinedDF[combinedDF['modelParts'] == 27 ]\n",
      "combinedDF_part28 = combinedDF[combinedDF['modelParts'] == 28 ]\n",
      "combinedDF_part29 = combinedDF[combinedDF['modelParts'] == 29 ]\n",
      "combinedDF_part30 = combinedDF[combinedDF['modelParts'] == 30 ]\n",
      "combinedDF_Array = [\n",
      "combinedDF_part0,combinedDF_part1,combinedDF_part2,combinedDF_part3,combinedDF_part4,combinedDF_part5,combinedDF_part6,combinedDF_part7,combinedDF_part8,combinedDF_part9,combinedDF_part10,combinedDF_part11,combinedDF_part12,combinedDF_part13,combinedDF_part14,combinedDF_part15,combinedDF_part16,combinedDF_part17,combinedDF_part18,combinedDF_part19,combinedDF_part20,combinedDF_part21,combinedDF_part22,combinedDF_part23,combinedDF_part24,combinedDF_part25,combinedDF_part26,combinedDF_part27,combinedDF_part28,combinedDF_part29,combinedDF_part30,"
     ]
    }
   ],
   "source": [
    "for i in range(31):\n",
    "    print(\"combinedDF_part\" + str(i), \"= combinedDF[combinedDF['modelParts'] ==\", i, \"]\")\n",
    "\n",
    "print('combinedDF_Array = [')\n",
    "for i in range(31):\n",
    "    print(\"combinedDF_part\" + str(i) + \",\", end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDF_part0 = combinedDF[combinedDF['modelParts'] == 0 ]\n",
    "combinedDF_part1 = combinedDF[combinedDF['modelParts'] == 1 ]\n",
    "combinedDF_part2 = combinedDF[combinedDF['modelParts'] == 2 ]\n",
    "combinedDF_part3 = combinedDF[combinedDF['modelParts'] == 3 ]\n",
    "combinedDF_part4 = combinedDF[combinedDF['modelParts'] == 4 ]\n",
    "combinedDF_part5 = combinedDF[combinedDF['modelParts'] == 5 ]\n",
    "combinedDF_part6 = combinedDF[combinedDF['modelParts'] == 6 ]\n",
    "combinedDF_part7 = combinedDF[combinedDF['modelParts'] == 7 ]\n",
    "combinedDF_part8 = combinedDF[combinedDF['modelParts'] == 8 ]\n",
    "combinedDF_part9 = combinedDF[combinedDF['modelParts'] == 9 ]\n",
    "combinedDF_part10 = combinedDF[combinedDF['modelParts'] == 10 ]\n",
    "combinedDF_part11 = combinedDF[combinedDF['modelParts'] == 11 ]\n",
    "combinedDF_part12 = combinedDF[combinedDF['modelParts'] == 12 ]\n",
    "combinedDF_part13 = combinedDF[combinedDF['modelParts'] == 13 ]\n",
    "combinedDF_part14 = combinedDF[combinedDF['modelParts'] == 14 ]\n",
    "combinedDF_part15 = combinedDF[combinedDF['modelParts'] == 15 ]\n",
    "combinedDF_part16 = combinedDF[combinedDF['modelParts'] == 16 ]\n",
    "combinedDF_part17 = combinedDF[combinedDF['modelParts'] == 17 ]\n",
    "combinedDF_part18 = combinedDF[combinedDF['modelParts'] == 18 ]\n",
    "combinedDF_part19 = combinedDF[combinedDF['modelParts'] == 19 ]\n",
    "combinedDF_part20 = combinedDF[combinedDF['modelParts'] == 20 ]\n",
    "combinedDF_part21 = combinedDF[combinedDF['modelParts'] == 21 ]\n",
    "combinedDF_part22 = combinedDF[combinedDF['modelParts'] == 22 ]\n",
    "combinedDF_part23 = combinedDF[combinedDF['modelParts'] == 23 ]\n",
    "combinedDF_part24 = combinedDF[combinedDF['modelParts'] == 24 ]\n",
    "combinedDF_part25 = combinedDF[combinedDF['modelParts'] == 25 ]\n",
    "combinedDF_part26 = combinedDF[combinedDF['modelParts'] == 26 ]\n",
    "combinedDF_part27 = combinedDF[combinedDF['modelParts'] == 27 ]\n",
    "combinedDF_part28 = combinedDF[combinedDF['modelParts'] == 28 ]\n",
    "combinedDF_part29 = combinedDF[combinedDF['modelParts'] == 29 ]\n",
    "combinedDF_part30 = combinedDF[combinedDF['modelParts'] == 30 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array is for the iteration to save the 30 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDF_Array = [combinedDF_part0,combinedDF_part1,combinedDF_part2,combinedDF_part3,combinedDF_part4,combinedDF_part5,combinedDF_part6,combinedDF_part7,combinedDF_part8,combinedDF_part9,combinedDF_part10,combinedDF_part11,combinedDF_part12,combinedDF_part13,combinedDF_part14,combinedDF_part15,combinedDF_part16,combinedDF_part17,combinedDF_part18,combinedDF_part19,combinedDF_part20,combinedDF_part21,combinedDF_part22,combinedDF_part23,combinedDF_part24,combinedDF_part25,combinedDF_part26,combinedDF_part27,combinedDF_part28,combinedDF_part29,combinedDF_part30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierDF = combinedDF.copy()\n",
    "\n",
    "for i in range(31):\n",
    "    classifierDF = combinedDF_Array[i].copy()\n",
    "    classifierDF = classifierDF[['carparkNoIndicator', 'timeInSec', 'dayOfWeek', 'lotsAvailable']]\n",
    "\n",
    "    X2 = classifierDF[['carparkNoIndicator', 'timeInSec', 'dayOfWeek']]\n",
    "    y2 = classifierDF['lotsAvailable'].values.reshape(-1,1)\n",
    "    DTM = regr.fit(X2, y2)\n",
    "\n",
    "    model_file = 'DT_model' + str(i) + '.sav'\n",
    "    pickle.dump(DTM, open(model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template to load the model and try the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carparkNumber = str(input(\"Enter the carpark number. \"))\n",
    "timeInSec = str(input(\"Enter the time in HH:MM format to check. \"))\n",
    "dayInTheWeek = int(input(\"Enter the day of week. \"))\n",
    "\n",
    "carpark = identifyCarpark(carparkNumber)\n",
    "convertedTime = convertTimeToSec(timeInSec + \":00\")\n",
    "\n",
    "int(DTM.predict([[carpark, convertedTime, dayInTheWeek]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
